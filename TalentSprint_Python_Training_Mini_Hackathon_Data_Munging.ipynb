{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TalentSprint Python Training -  Mini_Hackathon_Data_Munging.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narenoffl/TalentSpring-TsCoE-Python-Training-for-ML-AI/blob/master/TalentSprint_Python_Training_Mini_Hackathon_Data_Munging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIfh2REWFr6p",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrIlNFZeKMsx",
        "colab_type": "text"
      },
      "source": [
        "At the end of this experiment, you will be able to:\n",
        "\n",
        "* Perform Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5DokZ7MF1P_",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsMUO2zddtz6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3vgcWwOF2cK",
        "colab_type": "text"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqJ1h77-KMsy",
        "colab_type": "text"
      },
      "source": [
        "We will be using district wise demographics, enrollments, school and teacher indicator data to predict whether the literacy rate is high / medium / low in each district."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md2IjdMdGCWm",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B5ztQVbKMsz",
        "colab_type": "text"
      },
      "source": [
        "Data preprocessing is an important step of solving every machine learning problem. Most of\n",
        "the datasets used with Machine Learning problems need to be processed / cleaned / transformed\n",
        "so that a Machine Learning algorithm can be trained on it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsxaJLZAKMs0",
        "colab_type": "text"
      },
      "source": [
        "There are different steps involved for Data Preprocessing. These steps are as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF3Eg-5pKMs1",
        "colab_type": "text"
      },
      "source": [
        "    1. Data Cleaning → In this step the primary focus is on\n",
        "        -Handling missing data\n",
        "        -Handling nosiy data\n",
        "        -Detection and removal of outliers\n",
        "    \n",
        "    2. Data Integration → This process is used when data is gathered from various data sources\n",
        "    and data are combined to form consistent data. This data after performing cleaning is used\n",
        "    for analysis.\n",
        "    \n",
        "    3. Data Transformation → In this step we will convert the raw data into a specified for-\n",
        "    mat according to the need of the model we are building. There are many options used for\n",
        "    transforming the data as below:\n",
        "        -Normalization\n",
        "        -Aggregation\n",
        "        -Generalization\n",
        "        \n",
        "    4. Data Reduction → After data transformation and scaling the redundancy within the data\n",
        "    is removed and efficiently organizing the data is performed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd9cGZeydAyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to download the data (you will get the zip file)\n",
        "!wget https://cdn.talentsprint.com/aiml/Experiment_related_data/data-20190108T113429Z-001.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0OLk-Y-8yfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to unzip the data\n",
        "!unzip data-20190108T113429Z-001.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7VD8dJgGhVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9utRh_WiPNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDWnvJ6QiRB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZSlj_nWKMs4",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 1 \n",
        "We have four different files\n",
        "\n",
        "* Districtwise_Basicdata.csv\n",
        "* Districtwise_Enrollment_details_indicator.csv\n",
        "* Districtwise_SchoolData.csv\n",
        "* Districtwise_Teacher_indicator.csv\n",
        "These files contain the neccesary data to solve the problem.\n",
        "Load all the files correctly, after observing the header level details, data records etc\n",
        "\n",
        "Hint : Use read_csv from pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vu4wIbLfeuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMYVzPJbV3_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_ePXsjclHI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basicdata = pd.read_csv('/content/drive/My Drive/mini hackathon dataset/Districtwise_Basicdata.csv',header = [1])\n",
        "basicdata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSJL4c3BWF7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enrollmentData = pd.read_csv('/content/drive/My Drive/mini hackathon dataset/Districtwise_Enrollment_details_indicator.csv',header = [3])\n",
        "enrollmentData.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H4lHzC2WZ58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "schoolData = pd.read_csv('/content/drive/My Drive/mini hackathon dataset/Districtwise_SchoolData.csv',header = [3])\n",
        "schoolData.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MRLDrCaX3l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacherData = pd.read_csv('/content/drive/My Drive/mini hackathon dataset/Districtwise_Teacher_indicator.csv',header = [3])\n",
        "teacherData.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmasGuOJav96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mergeData = pd.concat([basicdata, enrollmentData, schoolData, teacherData], axis = 1, join = 'inner')\n",
        "mergeData = mergeData.loc[:,~mergeData.columns.duplicated()]\n",
        "mergeData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2A3OKraKMs9",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 2  \n",
        "\n",
        "* Remove the unwanted columns, which are unlikely to contribute for the prediction of overall literacy grade. The decision of what constitutes unwanted columns depends on how it effects your final accuracy (and very little on your domain understanding of education sector in India; you're encouraged however to exercise some domain understanding too if you wish)\n",
        "\n",
        "**Hint** use pandas drop function to drop your choice of unwanted columns (if any).\n",
        "\n",
        "\n",
        "* As the required data is present in different files, we need to integrate all the four to make single dataframe/dataset. For that purpose, create a unique identifier for each row in all the dataframes so that it can be used to map the data in different files correctly\n",
        "* Join/integrate this data \n",
        "\n",
        "Example : data of the district ananthapur in Andrapradesh, which present in different files should form a single row \n",
        "\n",
        "Hint : \n",
        "* Use the combination of year, statecode, district code as unique identifier \n",
        "\n",
        "* Refer the following link for merge, join and concat syntaxes:  \n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/merging.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le5wGzUuKMs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mergeData.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDFg350LmYxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mergeData.replace({'High':1, 'Medium':0, 'Low':-1}, inplace = True)\n",
        "mdco = mergeData.corr()\n",
        "lst = mdco.overall_lit[((mdco.overall_lit > 0.35) | (mdco.overall_lit < -0.35)) & (mdco.overall_lit!=1)]\n",
        "lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jcX4aRsKMtE",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 3 \n",
        "\n",
        "* Overall_lit is our target variable, which we need to predict. Delete the row with missing overall_lit column\n",
        "* Take a call to replace the missing values in any other column appropriately with mean/median/mode\n",
        "* Convert categorical values to numerical values\n",
        "Example : If a feature contains categorical values such as dog, cat, mouse etc then replace them with 1, 2, 3 etc or using one hot encoding (your judgement)\n",
        "\n",
        "*Hint* :\n",
        "* Use pandas fillna function to replace the missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzsY-knQKMtI",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 4 \n",
        "\n",
        "Use the functions below to adjust the outliers\n",
        "\n",
        "smooth_out function takes pandas dataframe as input and caculates mean, standard deviation of every column to check whether all the values in that lies within the range of mean +/- 2*standard_deviation of that column or not.\n",
        "If any of the values are not present in that boundary, then that values is brought on to the boundary.\n",
        "\n",
        "**Hint:** Should  the index column be normalized too? \n",
        "\n",
        "<img src=\"https://cdn.talentsprint.com/aiml/Experiment_related_data/normal_dist.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhdy63OSKMtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to clip and clam the data\n",
        "def clip_clamp(x, mean, sd):\n",
        "    # Checking whether the value is less than a differenced value between mean and standard deviation.\n",
        "    if x < mean - 2*sd :\n",
        "        return mean - 2*sd\n",
        "    #Checking whether the value is greater than a differenced value between mean and standard deviation.\n",
        "    elif x > mean + 2*sd :\n",
        "        return mean + 2*sd\n",
        "    # If above two conditions are not statisfied we will return the original value\n",
        "    else :\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXWSJ2wCKMtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to smooth the data\n",
        "def smooth_out(Total_data):\n",
        "    for i in Total_data.columns:\n",
        "        # Calculating the mean value\n",
        "        mean = np.mean(Total_data[i].values, axis=0)\n",
        "        # Calculating the standard deviation value\n",
        "        sd = np.std(Total_data[i].values, axis=0)\n",
        "        # Calculating the corrected value using clip and clamp function\n",
        "        corrected = np.array([clip_clamp(x, mean, sd) for x in Total_data[i].values])\n",
        "        # Storing the data in form of series\n",
        "        Total_data[i] = pd.Series(corrected, index=Total_data[i].index)\n",
        "    return Total_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dMbvU-KKMtY",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 5 \n",
        "\n",
        "Use the function below (corr_features) to identify uncorrelated features and remove the remaining features\n",
        "* corr_features takes pandas dataframe, columns in the dataframe and bar (corelation co-efficient)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgJeGouOKMtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to find uncorrelated features\n",
        "def corr_features(df,cols,bar=0.9):\n",
        "    for c,i in enumerate(cols[:-1]):\n",
        "        col_set = set(cols)\n",
        "        for j in cols[c+1:]:\n",
        "            if i==j:\n",
        "                continue\n",
        "           \n",
        "            score = df[i].corr(df[j])\n",
        "            \n",
        "            if score>bar:\n",
        "                cols = list(col_set-set([j]))\n",
        "            if score<-bar:\n",
        "                cols = list(col_set-set([j]))\n",
        "    return cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5njOPWIXKMtd",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 6 \n",
        "\n",
        "Perform Mean Correction and Standard Scaling on the data feature/column wise.\n",
        "\n",
        "**Hint:** In order to understand the idea behind the terms used above, you may refer the following link: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QugqX021KMtl",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 7 **(Optional)**\n",
        "\n",
        "you can apply different classifiers(from sklearn) on the preprocessed data ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6ka-fmz8gGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def callKnn(data,targets):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.33)\n",
        "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "    neigh.fit(X_train, y_train)\n",
        "    predicted_labels = neigh.predict(X_test)\n",
        "    return accuracy_score(y_test,predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzLzs-4KsKdo",
        "colab_type": "text"
      },
      "source": [
        "## **Direct Solutions for all other exercises** (including Ex 7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3InDQl1m0pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lst.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xDhAFA4nnPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_list = list(lst.index)\n",
        "x_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb_SSVihn5Ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indNo = list(map(lambda x:mergeData.columns.get_loc(x), x_list))\n",
        "indNo.append(mergeData.columns.get_loc('overall_lit'))\n",
        "indNo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qks7_oYOp62y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dit = {'overall_lit':mergeData.iloc[:,17], x_list[0]:mergeData.iloc[:,11], x_list[1]:mergeData.iloc[:,18], x_list[2]:mergeData.iloc[:,105], x_list[3]:mergeData.iloc[:,229], x_list[4]:mergeData.iloc[:,274], x_list[5]:mergeData.iloc[:,332], x_list[6]:mergeData.iloc[:,339], x_list[7]:mergeData.iloc[:,418]}\n",
        "final_data = pd.DataFrame(dit)\n",
        "final_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dqPUFdvqsbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REcYtu79KMtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_data.fillna(final_data.mean(), inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hU2poUeKMtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gisomp5aa9Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_data.boxplot(figsize = (20,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "988wdlpDKMtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.heatmap(final_data.corr() , cmap=\"Greens\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEjD56Puavy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = final_data.iloc[:,1:]\n",
        "y = final_data.iloc[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbXsaxRkzZiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu50dJFyzbp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "pred = lr.predict(X_test)\n",
        "pred = pred.round()\n",
        "pred = pred.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "df = pd.DataFrame({'ACTUAL VALUE':y_test, 'PREDICTED VALUE':pred})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw6kWpTJzpEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "import numpy as np\n",
        "print('RMSE' ,np.sqrt(mean_squared_error(pred,y_test)))\n",
        "print('R2score' ,r2_score(pred,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhNUl1x2zzmg",
        "colab_type": "text"
      },
      "source": [
        "**Process of Data Filtering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0FpkzbB0BAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,9):\n",
        "  q1 = final_data.iloc[:,i].quantile(0.25)\n",
        "  q3 = final_data.iloc[:,i].quantile(0.75)\n",
        "  IQR = q3 - q1\n",
        "  minim = q1 - 1.5*IQR\n",
        "  maxim = q3 + 1.5*IQR\n",
        "  ind2 = final_data[(final_data.iloc[:,i] >= maxim)|(final_data.iloc[:,i] <= minim)].index\n",
        "  final_data.drop(index = ind2, inplace = True)\n",
        "final_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ewAV4c0d6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = final_data.iloc[:,1:]\n",
        "y = final_data.iloc[:,0]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "y_pred = y_pred.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "df2 = pd.DataFrame({'ACTUAL VALUES':y_test, 'PREDICTED VALUES':y_pred})\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol479phg0ioF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "print('RMSE' ,np.sqrt(mean_squared_error(y_pred,y_test)))\n",
        "print('R2score' ,r2_score(y_pred,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F81VryXd0rC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_data.boxplot(figsize = (20,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms4lvFTJ1PlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}